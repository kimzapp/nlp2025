{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8a35120d",
      "metadata": {
        "id": "8a35120d"
      },
      "source": [
        "### Thiết lập môi trường và tải dữ liệu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7676d6f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "e7676d6f",
        "outputId": "3ddec3fc-535d-4a37-fbd3-2f326e419041"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train shape: (8954, 2)\n",
            "Validation shape: (1076, 2)\n",
            "Test shape: (1076, 2)\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_train\",\n  \"rows\": 8954,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8954,\n        \"samples\": [\n          \"please show me the list that i have\",\n          \"raise lights to full power\",\n          \"i think you made some mistake, please check it.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 64,\n        \"samples\": [\n          \"recommendation_events\",\n          \"takeaway_query\",\n          \"alarm_query\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df_train"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-174bd814-f982-4146-adfc-2ca823ea0149\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>what alarms do i have set right now</td>\n",
              "      <td>alarm_query</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>checkout today alarm of meeting</td>\n",
              "      <td>alarm_query</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>report alarm settings</td>\n",
              "      <td>alarm_query</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>see see for me the alarms that you have set to...</td>\n",
              "      <td>alarm_query</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>is there an alarm for ten am</td>\n",
              "      <td>alarm_query</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-174bd814-f982-4146-adfc-2ca823ea0149')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-174bd814-f982-4146-adfc-2ca823ea0149 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-174bd814-f982-4146-adfc-2ca823ea0149');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-99ec92aa-4ede-4ec5-ab19-ddefcbb47c61\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-99ec92aa-4ede-4ec5-ab19-ddefcbb47c61')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-99ec92aa-4ede-4ec5-ab19-ddefcbb47c61 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                text     category\n",
              "0                what alarms do i have set right now  alarm_query\n",
              "1                    checkout today alarm of meeting  alarm_query\n",
              "2                              report alarm settings  alarm_query\n",
              "3  see see for me the alarms that you have set to...  alarm_query\n",
              "4                       is there an alarm for ten am  alarm_query"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "data_path = r'/content'\n",
        "train_path = os.path.join(data_path, 'train.csv')\n",
        "val_path =  os.path.join(data_path, 'val.csv')\n",
        "test_path = os.path.join(data_path, 'test.csv')\n",
        "\n",
        "# Dữ liệu có thể được phân tách bằng tab và không có header\n",
        "df_train = pd.read_csv(train_path)\n",
        "df_val = pd.read_csv(val_path)\n",
        "df_test = pd.read_csv(test_path)\n",
        "print(\"Train shape:\", df_train.shape)\n",
        "print(\"Validation shape:\", df_val.shape)\n",
        "print(\"Test shape:\", df_test.shape)\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc5faba1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc5faba1",
        "outputId": "36a95316-487e-49e2-aa0d-c0448c6b9f2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of classes: 64\n"
          ]
        }
      ],
      "source": [
        "# label encoding\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "df_train['label_encoded'] = label_encoder.fit_transform(df_train['category'])\n",
        "df_val['label_encoded'] = label_encoder.transform(df_val['category'])\n",
        "df_test['label_encoded'] = label_encoder.transform(df_test['category'])\n",
        "\n",
        "num_classes = len(label_encoder.classes_)\n",
        "print(\"Number of classes:\", num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e273738",
      "metadata": {
        "id": "7e273738"
      },
      "source": [
        "### Pipeline TF-IDF + Logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b868f16d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b868f16d",
        "outputId": "1bf6cf37-6f81-4134-c189-c991a596dfce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.95      0.92        19\n",
            "           1       1.00      0.73      0.84        11\n",
            "           2       0.77      0.89      0.83        19\n",
            "           3       1.00      0.75      0.86         8\n",
            "           4       0.92      0.80      0.86        15\n",
            "           5       0.93      1.00      0.96        13\n",
            "           6       0.45      0.53      0.49        19\n",
            "           7       0.89      0.89      0.89        19\n",
            "           8       0.87      0.68      0.76        19\n",
            "           9       0.59      0.68      0.63        19\n",
            "          10       0.67      0.75      0.71         8\n",
            "          11       0.74      0.89      0.81        19\n",
            "          12       0.78      0.88      0.82         8\n",
            "          13       0.83      0.79      0.81        19\n",
            "          14       0.92      0.63      0.75        19\n",
            "          15       0.81      0.89      0.85        19\n",
            "          16       1.00      1.00      1.00        19\n",
            "          17       1.00      1.00      1.00        19\n",
            "          18       1.00      1.00      1.00        19\n",
            "          19       0.90      1.00      0.95        19\n",
            "          20       1.00      0.95      0.97        19\n",
            "          21       1.00      1.00      1.00        12\n",
            "          22       0.95      1.00      0.97        19\n",
            "          23       0.95      1.00      0.97        19\n",
            "          24       0.36      0.26      0.30        19\n",
            "          25       0.90      1.00      0.95        19\n",
            "          26       1.00      1.00      1.00        16\n",
            "          27       1.00      0.95      0.97        19\n",
            "          28       0.75      0.79      0.77        19\n",
            "          29       0.91      0.83      0.87        12\n",
            "          30       0.89      0.89      0.89        19\n",
            "          31       0.67      0.67      0.67         3\n",
            "          32       1.00      0.86      0.92        14\n",
            "          33       0.80      0.89      0.84         9\n",
            "          34       0.78      1.00      0.88         7\n",
            "          35       0.68      0.79      0.73        19\n",
            "          36       0.75      0.79      0.77        19\n",
            "          37       0.85      0.89      0.87        19\n",
            "          38       0.65      0.61      0.63        18\n",
            "          39       0.71      0.53      0.61        19\n",
            "          40       1.00      0.57      0.73         7\n",
            "          41       0.75      0.63      0.69        19\n",
            "          42       0.95      0.95      0.95        19\n",
            "          43       0.81      0.68      0.74        19\n",
            "          44       0.58      0.74      0.65        19\n",
            "          45       1.00      0.84      0.91        19\n",
            "          46       0.89      0.84      0.86        19\n",
            "          47       0.94      0.89      0.92        19\n",
            "          48       0.82      0.95      0.88        19\n",
            "          49       0.48      0.58      0.52        19\n",
            "          50       0.92      0.86      0.89        14\n",
            "          51       1.00      0.95      0.97        19\n",
            "          52       0.83      0.79      0.81        19\n",
            "          53       0.81      0.89      0.85        19\n",
            "          54       1.00      1.00      1.00        10\n",
            "          55       0.95      1.00      0.97        19\n",
            "          56       0.80      0.89      0.84        18\n",
            "          57       0.83      0.79      0.81        19\n",
            "          58       0.89      0.89      0.89        19\n",
            "          59       0.68      0.79      0.73        19\n",
            "          60       1.00      1.00      1.00        18\n",
            "          61       0.94      0.79      0.86        19\n",
            "          62       1.00      0.95      0.97        19\n",
            "          63       0.62      0.68      0.65        19\n",
            "\n",
            "    accuracy                           0.84      1076\n",
            "   macro avg       0.85      0.83      0.84      1076\n",
            "weighted avg       0.84      0.84      0.84      1076\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "# 1. Tạo một pipeline với TfidfVectorizer và LogisticRegression\n",
        "tfidf_lr_pipeline = make_pipeline(\n",
        "    TfidfVectorizer(max_features=5000),\n",
        "    LogisticRegression(max_iter=1000)\n",
        ")\n",
        "# 2. Huấn luyện pipeline trên tập train\n",
        "tfidf_lr_pipeline.fit(df_train['text'], df_train['label_encoded'])\n",
        "\n",
        "# 3. Đánh giá trên tập test\n",
        "y_pred = tfidf_lr_pipeline.predict(df_test['text'])\n",
        "print(classification_report(df_test['label_encoded'], y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2df43f57",
      "metadata": {
        "id": "2df43f57"
      },
      "source": [
        "### Pipeline Word2Vec (mean) + Dense layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69efd1bf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69efd1bf",
        "outputId": "5e8955e4-2b07-4d8e-fd8c-15e57de294e1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.0171 - loss: 4.1596 - val_accuracy: 0.0372 - val_loss: 4.0762\n",
            "Epoch 2/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0447 - loss: 4.0638 - val_accuracy: 0.0651 - val_loss: 3.9617\n",
            "Epoch 3/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0478 - loss: 3.9577 - val_accuracy: 0.0725 - val_loss: 3.8432\n",
            "Epoch 4/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0638 - loss: 3.8479 - val_accuracy: 0.0799 - val_loss: 3.7579\n",
            "Epoch 5/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0703 - loss: 3.7833 - val_accuracy: 0.0836 - val_loss: 3.6878\n",
            "Epoch 6/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0767 - loss: 3.7114 - val_accuracy: 0.1078 - val_loss: 3.6195\n",
            "Epoch 7/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0894 - loss: 3.6502 - val_accuracy: 0.1115 - val_loss: 3.5604\n",
            "Epoch 8/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0968 - loss: 3.5868 - val_accuracy: 0.1180 - val_loss: 3.5226\n",
            "Epoch 9/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1032 - loss: 3.5541 - val_accuracy: 0.1171 - val_loss: 3.5032\n",
            "Epoch 10/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1148 - loss: 3.5173 - val_accuracy: 0.1571 - val_loss: 3.4327\n",
            "Epoch 11/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1203 - loss: 3.4674 - val_accuracy: 0.1673 - val_loss: 3.3907\n",
            "Epoch 12/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1208 - loss: 3.4237 - val_accuracy: 0.1682 - val_loss: 3.3733\n",
            "Epoch 13/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1283 - loss: 3.4216 - val_accuracy: 0.1626 - val_loss: 3.3339\n",
            "Epoch 14/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1296 - loss: 3.3760 - val_accuracy: 0.1747 - val_loss: 3.2975\n",
            "Epoch 15/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1407 - loss: 3.3441 - val_accuracy: 0.1794 - val_loss: 3.2980\n",
            "Epoch 16/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1428 - loss: 3.3244 - val_accuracy: 0.1775 - val_loss: 3.2592\n",
            "Epoch 17/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1510 - loss: 3.3113 - val_accuracy: 0.1794 - val_loss: 3.2433\n",
            "Epoch 18/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1510 - loss: 3.3024 - val_accuracy: 0.2007 - val_loss: 3.2046\n",
            "Epoch 19/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1620 - loss: 3.2831 - val_accuracy: 0.2091 - val_loss: 3.1939\n",
            "Epoch 20/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1561 - loss: 3.2690 - val_accuracy: 0.1887 - val_loss: 3.1636\n",
            "Epoch 21/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1647 - loss: 3.2186 - val_accuracy: 0.2063 - val_loss: 3.1493\n",
            "Epoch 22/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1599 - loss: 3.2241 - val_accuracy: 0.2017 - val_loss: 3.1240\n",
            "Epoch 23/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1632 - loss: 3.2155 - val_accuracy: 0.2212 - val_loss: 3.1192\n",
            "Epoch 24/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1737 - loss: 3.1841 - val_accuracy: 0.2175 - val_loss: 3.0828\n",
            "Epoch 25/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1725 - loss: 3.1786 - val_accuracy: 0.2230 - val_loss: 3.0825\n",
            "Epoch 26/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1710 - loss: 3.1627 - val_accuracy: 0.2091 - val_loss: 3.0563\n",
            "Epoch 27/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1769 - loss: 3.1411 - val_accuracy: 0.2305 - val_loss: 3.0420\n",
            "Epoch 28/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1857 - loss: 3.1194 - val_accuracy: 0.2286 - val_loss: 3.0352\n",
            "Epoch 29/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1901 - loss: 3.0974 - val_accuracy: 0.2361 - val_loss: 3.0081\n",
            "Epoch 30/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1879 - loss: 3.1046 - val_accuracy: 0.2361 - val_loss: 3.0039\n",
            "Epoch 31/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1949 - loss: 3.1052 - val_accuracy: 0.2230 - val_loss: 2.9783\n",
            "Epoch 32/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1943 - loss: 3.0668 - val_accuracy: 0.2379 - val_loss: 2.9924\n",
            "Epoch 33/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1976 - loss: 3.0667 - val_accuracy: 0.2351 - val_loss: 2.9474\n",
            "Epoch 34/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2049 - loss: 3.0338 - val_accuracy: 0.2426 - val_loss: 2.9461\n",
            "Epoch 35/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1972 - loss: 3.0361 - val_accuracy: 0.2639 - val_loss: 2.9241\n",
            "Epoch 36/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2009 - loss: 3.0127 - val_accuracy: 0.2593 - val_loss: 2.9047\n",
            "Epoch 37/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2078 - loss: 3.0013 - val_accuracy: 0.2639 - val_loss: 2.9156\n",
            "Epoch 38/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2123 - loss: 2.9948 - val_accuracy: 0.2463 - val_loss: 2.8954\n",
            "Epoch 39/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2127 - loss: 2.9875 - val_accuracy: 0.2491 - val_loss: 2.8754\n",
            "Epoch 40/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2095 - loss: 2.9895 - val_accuracy: 0.2639 - val_loss: 2.8665\n",
            "Epoch 41/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2183 - loss: 2.9535 - val_accuracy: 0.2677 - val_loss: 2.8584\n",
            "Epoch 42/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2202 - loss: 2.9253 - val_accuracy: 0.2742 - val_loss: 2.8271\n",
            "Epoch 43/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2166 - loss: 2.9589 - val_accuracy: 0.2872 - val_loss: 2.8152\n",
            "Epoch 44/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2342 - loss: 2.9321 - val_accuracy: 0.2825 - val_loss: 2.8199\n",
            "Epoch 45/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2296 - loss: 2.9364 - val_accuracy: 0.2704 - val_loss: 2.8191\n",
            "Epoch 46/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2362 - loss: 2.9042 - val_accuracy: 0.2881 - val_loss: 2.7978\n",
            "Epoch 47/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2259 - loss: 2.9070 - val_accuracy: 0.2779 - val_loss: 2.7901\n",
            "Epoch 48/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2331 - loss: 2.8896 - val_accuracy: 0.2825 - val_loss: 2.7846\n",
            "Epoch 49/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2243 - loss: 2.8969 - val_accuracy: 0.2881 - val_loss: 2.7782\n",
            "Epoch 50/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2390 - loss: 2.8883 - val_accuracy: 0.2872 - val_loss: 2.7609\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3185 - loss: 2.6314\n",
            "Test accuracy: 0.2815985083580017\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from gensim.models import Word2Vec\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "# 1. Huấn luyện mô hình Word2Vec trên dữ liệu text của bạn\n",
        "sentences = [text.split() for text in df_train['text']]\n",
        "w2v_model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "# 2. Viết hàm để chuyển mỗi câu thành vector trung bình\n",
        "def sentence_to_avg_vector(text, model):\n",
        "    # ... (Implement logic)\n",
        "    vectors = [model.wv[word] for word in text.split() if word in model.wv]\n",
        "    avg_vector = np.mean(vectors, axis=0) if vectors else np.zeros(model.vector_size)\n",
        "    return avg_vector\n",
        "\n",
        "# 3. Tạo dữ liệu train/val/test X_train_avg, X_val_avg, X_test_avg\n",
        "X_train_avg = np.array([sentence_to_avg_vector(text, w2v_model) for text in df_train['text']])\n",
        "X_val_avg = np.array([sentence_to_avg_vector(text, w2v_model) for text in df_val['text']])\n",
        "X_test_avg = np.array([sentence_to_avg_vector(text, w2v_model) for text in df_test['text']])\n",
        "y_train = df_train['label_encoded'].values\n",
        "y_val = df_val['label_encoded'].values\n",
        "y_test = df_test['label_encoded'].values\n",
        "\n",
        "# 4. Xây dựng mô hình Sequential của Keras\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(w2v_model.vector_size,)),\n",
        "    Dropout(0.5),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# 5. Compile, huấn luyện và đánh giá mô hình\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(X_train_avg, y_train, validation_data=(X_val_avg, y_val), epochs=50, batch_size=32)\n",
        "test_loss, test_acc = model.evaluate(X_test_avg, y_test)\n",
        "print(f\"Test accuracy: {test_acc}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "669d60d0",
      "metadata": {
        "id": "669d60d0"
      },
      "source": [
        "### Mô hình nâng cao (Embedding pre-trained + LSTM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "caf7c6f6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caf7c6f6",
        "outputId": "cb0f4514-9b8c-41b7-e577-4deed6fd9f97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 147ms/step - accuracy: 0.0171 - loss: 4.1441 - val_accuracy: 0.0344 - val_loss: 4.0009\n",
            "Epoch 2/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 146ms/step - accuracy: 0.0397 - loss: 4.0113 - val_accuracy: 0.0465 - val_loss: 3.8727\n",
            "Epoch 3/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 144ms/step - accuracy: 0.0408 - loss: 3.9230 - val_accuracy: 0.0511 - val_loss: 3.8630\n",
            "Epoch 4/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 146ms/step - accuracy: 0.0505 - loss: 3.8627 - val_accuracy: 0.0623 - val_loss: 3.7638\n",
            "Epoch 5/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 142ms/step - accuracy: 0.0473 - loss: 3.8253 - val_accuracy: 0.0716 - val_loss: 3.7439\n",
            "Epoch 6/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 142ms/step - accuracy: 0.0635 - loss: 3.8074 - val_accuracy: 0.0725 - val_loss: 3.7206\n",
            "Epoch 7/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 144ms/step - accuracy: 0.0618 - loss: 3.7629 - val_accuracy: 0.0846 - val_loss: 3.6709\n",
            "Epoch 8/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 141ms/step - accuracy: 0.0672 - loss: 3.7387 - val_accuracy: 0.0725 - val_loss: 3.6615\n",
            "Epoch 9/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 173ms/step - accuracy: 0.0639 - loss: 3.7286 - val_accuracy: 0.0809 - val_loss: 3.6630\n",
            "Epoch 10/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 178ms/step - accuracy: 0.0703 - loss: 3.7161 - val_accuracy: 0.0809 - val_loss: 3.6454\n",
            "Epoch 11/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 166ms/step - accuracy: 0.0726 - loss: 3.6997 - val_accuracy: 0.0651 - val_loss: 3.7417\n",
            "Epoch 12/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 143ms/step - accuracy: 0.0732 - loss: 3.6934 - val_accuracy: 0.0790 - val_loss: 3.6065\n",
            "Epoch 13/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 145ms/step - accuracy: 0.0708 - loss: 3.6651 - val_accuracy: 0.0901 - val_loss: 3.6383\n",
            "Epoch 14/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 146ms/step - accuracy: 0.0683 - loss: 3.6777 - val_accuracy: 0.0911 - val_loss: 3.6036\n",
            "Epoch 15/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 144ms/step - accuracy: 0.0732 - loss: 3.6415 - val_accuracy: 0.0846 - val_loss: 3.5638\n",
            "Epoch 16/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 144ms/step - accuracy: 0.0818 - loss: 3.6225 - val_accuracy: 0.0232 - val_loss: 4.1817\n",
            "Epoch 17/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 145ms/step - accuracy: 0.0426 - loss: 3.9120 - val_accuracy: 0.0716 - val_loss: 3.5803\n",
            "Epoch 18/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 144ms/step - accuracy: 0.0767 - loss: 3.6635 - val_accuracy: 0.1013 - val_loss: 3.5315\n",
            "Epoch 19/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 145ms/step - accuracy: 0.0847 - loss: 3.6346 - val_accuracy: 0.0864 - val_loss: 3.5528\n",
            "Epoch 20/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 143ms/step - accuracy: 0.0880 - loss: 3.5863 - val_accuracy: 0.0697 - val_loss: 3.5886\n",
            "Epoch 21/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 143ms/step - accuracy: 0.0877 - loss: 3.5769 - val_accuracy: 0.1050 - val_loss: 3.4351\n",
            "Epoch 22/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 147ms/step - accuracy: 0.0988 - loss: 3.5090 - val_accuracy: 0.1208 - val_loss: 3.3988\n",
            "Epoch 23/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 143ms/step - accuracy: 0.0988 - loss: 3.4804 - val_accuracy: 0.1190 - val_loss: 3.3167\n",
            "Epoch 24/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 144ms/step - accuracy: 0.1043 - loss: 3.4785 - val_accuracy: 0.1078 - val_loss: 3.3398\n",
            "Epoch 25/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 146ms/step - accuracy: 0.0954 - loss: 3.4580 - val_accuracy: 0.1115 - val_loss: 3.3685\n",
            "Epoch 26/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 143ms/step - accuracy: 0.1018 - loss: 3.4145 - val_accuracy: 0.1106 - val_loss: 3.3217\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.1410 - loss: 3.3849\n",
            "Test accuracy with LSTM and pretrained embeddings: 0.11895910650491714\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM\n",
        "\n",
        "# 1. Tiền xử lý cho mô hình chuỗi\n",
        "# a. Tokenizer: Tạo vocab và chuyển text thành chuỗi chỉ số\n",
        "vocab_size = len(w2v_model.wv.index_to_key) + 1\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=\"<UNK>\")\n",
        "tokenizer.fit_on_texts(df_train['text'])\n",
        "train_sequences = tokenizer.texts_to_sequences(df_train['text'])\n",
        "# b. Padding: Đảm bảo các chuỗi có cùng độ dài\n",
        "max_len = 50\n",
        "X_train_pad = pad_sequences(train_sequences, maxlen=max_len, padding='post')\n",
        "val_sequences = tokenizer.texts_to_sequences(df_val['text'])\n",
        "X_val_pad = pad_sequences(val_sequences, maxlen=max_len, padding='post')\n",
        "test_sequences = tokenizer.texts_to_sequences(df_test['text'])\n",
        "X_test_pad = pad_sequences(test_sequences, maxlen=max_len, padding='post')\n",
        "\n",
        "# 2. Tạo ma trận trọng số cho Embedding Layer từ Word2Vec\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "embedding_dim = w2v_model.vector_size\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if word in w2v_model.wv:\n",
        "        embedding_matrix[i] = w2v_model.wv[word]\n",
        "\n",
        "# 3. Xây dựng mô hình Sequential với LSTM\n",
        "lstm_model_pretrained = Sequential([\n",
        "    Embedding(\n",
        "        input_dim=vocab_size,\n",
        "        output_dim=embedding_dim,\n",
        "        weights=[embedding_matrix], # Khởi tạo trọng số\n",
        "        input_length=max_len,\n",
        "        trainable=False # Đóng băng lớp Embedding\n",
        "    ),\n",
        "    LSTM(128, dropout=0.2, recurrent_dropout=0.2),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# 4. Compile, huấn luyện (sử dụng EarlyStopping) và đánh giá\n",
        "lstm_model_pretrained.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "history = lstm_model_pretrained.fit(\n",
        "    X_train_pad, y_train,\n",
        "    validation_data=(X_val_pad, y_val),\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "test_loss, test_acc = lstm_model_pretrained.evaluate(X_test_pad, y_test)\n",
        "print(f\"Test accuracy with LSTM and pretrained embeddings: {test_acc}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tTVK5-yhn4Fd",
      "metadata": {
        "id": "tTVK5-yhn4Fd"
      },
      "source": [
        "### Mô hình nâng cao (Embedding học từ đầu + LSTM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PyRbAuqpn8ZX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyRbAuqpn8ZX",
        "outputId": "4316c03a-99e7-45ec-ca9a-ded6ae9a8280"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m560/560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 155ms/step - accuracy: 0.0175 - loss: 4.1488 - val_accuracy: 0.0177 - val_loss: 4.1319\n",
            "Epoch 2/50\n",
            "\u001b[1m560/560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 157ms/step - accuracy: 0.0159 - loss: 4.1350 - val_accuracy: 0.0177 - val_loss: 4.1268\n",
            "Epoch 3/50\n",
            "\u001b[1m560/560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 156ms/step - accuracy: 0.0150 - loss: 4.1346 - val_accuracy: 0.0177 - val_loss: 4.1268\n",
            "Epoch 4/50\n",
            "\u001b[1m560/560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 159ms/step - accuracy: 0.0171 - loss: 4.1352 - val_accuracy: 0.0177 - val_loss: 4.1266\n",
            "Epoch 5/50\n",
            "\u001b[1m560/560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 157ms/step - accuracy: 0.0173 - loss: 4.1361 - val_accuracy: 0.0177 - val_loss: 4.1263\n",
            "Epoch 6/50\n",
            "\u001b[1m560/560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 157ms/step - accuracy: 0.0159 - loss: 4.1333 - val_accuracy: 0.0177 - val_loss: 4.1254\n",
            "Epoch 7/50\n",
            "\u001b[1m560/560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 156ms/step - accuracy: 0.0152 - loss: 4.1304 - val_accuracy: 0.0177 - val_loss: 4.1257\n",
            "Epoch 8/50\n",
            "\u001b[1m560/560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 157ms/step - accuracy: 0.0161 - loss: 4.1323 - val_accuracy: 0.0177 - val_loss: 4.1251\n",
            "Epoch 9/50\n",
            "\u001b[1m560/560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 156ms/step - accuracy: 0.0180 - loss: 4.1336 - val_accuracy: 0.0177 - val_loss: 4.1253\n",
            "Epoch 10/50\n",
            "\u001b[1m560/560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 158ms/step - accuracy: 0.0155 - loss: 4.1272 - val_accuracy: 0.0177 - val_loss: 4.1254\n",
            "Epoch 11/50\n",
            "\u001b[1m560/560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 156ms/step - accuracy: 0.0154 - loss: 4.1291 - val_accuracy: 0.0177 - val_loss: 4.1240\n",
            "Epoch 12/50\n",
            "\u001b[1m560/560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 157ms/step - accuracy: 0.0155 - loss: 4.1293 - val_accuracy: 0.0177 - val_loss: 4.1241\n",
            "Epoch 13/50\n",
            "\u001b[1m560/560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 157ms/step - accuracy: 0.0181 - loss: 4.1302 - val_accuracy: 0.0177 - val_loss: 4.1246\n",
            "Epoch 14/50\n",
            "\u001b[1m560/560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 163ms/step - accuracy: 0.0148 - loss: 4.1287 - val_accuracy: 0.0177 - val_loss: 4.1240\n",
            "Epoch 15/50\n",
            "\u001b[1m560/560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 157ms/step - accuracy: 0.0130 - loss: 4.1301 - val_accuracy: 0.0177 - val_loss: 4.1240\n",
            "Epoch 16/50\n",
            "\u001b[1m560/560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 157ms/step - accuracy: 0.0160 - loss: 4.1292 - val_accuracy: 0.0177 - val_loss: 4.1239\n",
            "Epoch 17/50\n",
            "\u001b[1m560/560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 158ms/step - accuracy: 0.0180 - loss: 4.1321 - val_accuracy: 0.0177 - val_loss: 4.1238\n",
            "Epoch 18/50\n",
            "\u001b[1m560/560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 157ms/step - accuracy: 0.0145 - loss: 4.1357 - val_accuracy: 0.0177 - val_loss: 4.1238\n",
            "Epoch 19/50\n",
            "\u001b[1m560/560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 159ms/step - accuracy: 0.0164 - loss: 4.1329 - val_accuracy: 0.0177 - val_loss: 4.1235\n",
            "Epoch 20/50\n",
            "\u001b[1m560/560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 157ms/step - accuracy: 0.0152 - loss: 4.1279 - val_accuracy: 0.0177 - val_loss: 4.1241\n",
            "Epoch 21/50\n",
            "\u001b[1m560/560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 157ms/step - accuracy: 0.0134 - loss: 4.1318 - val_accuracy: 0.0177 - val_loss: 4.1239\n",
            "Epoch 22/50\n",
            "\u001b[1m560/560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 157ms/step - accuracy: 0.0158 - loss: 4.1299 - val_accuracy: 0.0177 - val_loss: 4.1243\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.0093 - loss: 4.1538\n",
            "Test accuracy with LSTM and embeddings learned from scratch: 0.017657993361353874\n"
          ]
        }
      ],
      "source": [
        "# Dữ liệu đã được tiền xử lý (tokenized, padded) từ nhiệm vụ 3\n",
        "# 1. Xây dựng mô hình\n",
        "lstm_model_scratch = Sequential([\n",
        "    Embedding(\n",
        "        input_dim=vocab_size,\n",
        "        output_dim=100, # Chọn một chiều embedding, ví dụ 100\n",
        "        input_length=max_len\n",
        "        # Không có weights, trainable=True (mặc định)\n",
        "    ),\n",
        "    LSTM(128, dropout=0.2, recurrent_dropout=0.2),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# 2. Compile, huấn luyện và đánh giá mô hình\n",
        "lstm_model_scratch.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "history = lstm_model_scratch.fit(\n",
        "    X_train_pad, y_train,\n",
        "    validation_data=(X_val_pad, y_val),\n",
        "    epochs=50,\n",
        "    batch_size=16,\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "test_loss, test_acc = lstm_model_scratch.evaluate(X_test_pad, y_test)\n",
        "print(f\"Test accuracy with LSTM and embeddings learned from scratch: {test_acc}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "nlp2025",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
