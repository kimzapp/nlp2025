{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8a35120d",
      "metadata": {
        "id": "8a35120d"
      },
      "source": [
        "### Thiết lập môi trường và tải dữ liệu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e7676d6f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "e7676d6f",
        "outputId": "91eff3cc-d1ee-4dc6-e89a-995cec1d0c96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train shape: (8954, 2)\n",
            "Validation shape: (1076, 2)\n",
            "Test shape: (1076, 2)\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_train\",\n  \"rows\": 8954,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8954,\n        \"samples\": [\n          \"please show me the list that i have\",\n          \"raise lights to full power\",\n          \"i think you made some mistake, please check it.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 64,\n        \"samples\": [\n          \"recommendation_events\",\n          \"takeaway_query\",\n          \"alarm_query\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df_train"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-c21b6cac-5cbc-4140-a396-6300f98319c8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>what alarms do i have set right now</td>\n",
              "      <td>alarm_query</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>checkout today alarm of meeting</td>\n",
              "      <td>alarm_query</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>report alarm settings</td>\n",
              "      <td>alarm_query</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>see see for me the alarms that you have set to...</td>\n",
              "      <td>alarm_query</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>is there an alarm for ten am</td>\n",
              "      <td>alarm_query</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c21b6cac-5cbc-4140-a396-6300f98319c8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c21b6cac-5cbc-4140-a396-6300f98319c8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c21b6cac-5cbc-4140-a396-6300f98319c8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e070b1ec-1fac-4041-bbc0-e7ee3ef3e27f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e070b1ec-1fac-4041-bbc0-e7ee3ef3e27f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e070b1ec-1fac-4041-bbc0-e7ee3ef3e27f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                text     category\n",
              "0                what alarms do i have set right now  alarm_query\n",
              "1                    checkout today alarm of meeting  alarm_query\n",
              "2                              report alarm settings  alarm_query\n",
              "3  see see for me the alarms that you have set to...  alarm_query\n",
              "4                       is there an alarm for ten am  alarm_query"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "data_path = r'/content'\n",
        "train_path = os.path.join(data_path, 'train.csv')\n",
        "val_path =  os.path.join(data_path, 'val.csv')\n",
        "test_path = os.path.join(data_path, 'test.csv')\n",
        "\n",
        "# Dữ liệu có thể được phân tách bằng tab và không có header\n",
        "df_train = pd.read_csv(train_path)\n",
        "df_val = pd.read_csv(val_path)\n",
        "df_test = pd.read_csv(test_path)\n",
        "print(\"Train shape:\", df_train.shape)\n",
        "print(\"Validation shape:\", df_val.shape)\n",
        "print(\"Test shape:\", df_test.shape)\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "bc5faba1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc5faba1",
        "outputId": "f80529b1-4c12-4635-a261-76e8f074a04f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of classes: 64\n"
          ]
        }
      ],
      "source": [
        "# label encoding\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "df_train['label_encoded'] = label_encoder.fit_transform(df_train['category'])\n",
        "df_val['label_encoded'] = label_encoder.transform(df_val['category'])\n",
        "df_test['label_encoded'] = label_encoder.transform(df_test['category'])\n",
        "\n",
        "num_classes = len(label_encoder.classes_)\n",
        "print(\"Number of classes:\", num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e273738",
      "metadata": {
        "id": "7e273738"
      },
      "source": [
        "### Pipeline TF-IDF + Logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b868f16d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b868f16d",
        "outputId": "d9545892-902a-410f-949d-67ec71000abb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.95      0.92        19\n",
            "           1       1.00      0.73      0.84        11\n",
            "           2       0.77      0.89      0.83        19\n",
            "           3       1.00      0.75      0.86         8\n",
            "           4       0.92      0.80      0.86        15\n",
            "           5       0.93      1.00      0.96        13\n",
            "           6       0.45      0.53      0.49        19\n",
            "           7       0.89      0.89      0.89        19\n",
            "           8       0.87      0.68      0.76        19\n",
            "           9       0.59      0.68      0.63        19\n",
            "          10       0.67      0.75      0.71         8\n",
            "          11       0.74      0.89      0.81        19\n",
            "          12       0.78      0.88      0.82         8\n",
            "          13       0.83      0.79      0.81        19\n",
            "          14       0.92      0.63      0.75        19\n",
            "          15       0.81      0.89      0.85        19\n",
            "          16       1.00      1.00      1.00        19\n",
            "          17       1.00      1.00      1.00        19\n",
            "          18       1.00      1.00      1.00        19\n",
            "          19       0.90      1.00      0.95        19\n",
            "          20       1.00      0.95      0.97        19\n",
            "          21       1.00      1.00      1.00        12\n",
            "          22       0.95      1.00      0.97        19\n",
            "          23       0.95      1.00      0.97        19\n",
            "          24       0.36      0.26      0.30        19\n",
            "          25       0.90      1.00      0.95        19\n",
            "          26       1.00      1.00      1.00        16\n",
            "          27       1.00      0.95      0.97        19\n",
            "          28       0.75      0.79      0.77        19\n",
            "          29       0.91      0.83      0.87        12\n",
            "          30       0.89      0.89      0.89        19\n",
            "          31       0.67      0.67      0.67         3\n",
            "          32       1.00      0.86      0.92        14\n",
            "          33       0.80      0.89      0.84         9\n",
            "          34       0.78      1.00      0.88         7\n",
            "          35       0.68      0.79      0.73        19\n",
            "          36       0.75      0.79      0.77        19\n",
            "          37       0.85      0.89      0.87        19\n",
            "          38       0.65      0.61      0.63        18\n",
            "          39       0.71      0.53      0.61        19\n",
            "          40       1.00      0.57      0.73         7\n",
            "          41       0.75      0.63      0.69        19\n",
            "          42       0.95      0.95      0.95        19\n",
            "          43       0.81      0.68      0.74        19\n",
            "          44       0.58      0.74      0.65        19\n",
            "          45       1.00      0.84      0.91        19\n",
            "          46       0.89      0.84      0.86        19\n",
            "          47       0.94      0.89      0.92        19\n",
            "          48       0.82      0.95      0.88        19\n",
            "          49       0.48      0.58      0.52        19\n",
            "          50       0.92      0.86      0.89        14\n",
            "          51       1.00      0.95      0.97        19\n",
            "          52       0.83      0.79      0.81        19\n",
            "          53       0.81      0.89      0.85        19\n",
            "          54       1.00      1.00      1.00        10\n",
            "          55       0.95      1.00      0.97        19\n",
            "          56       0.80      0.89      0.84        18\n",
            "          57       0.83      0.79      0.81        19\n",
            "          58       0.89      0.89      0.89        19\n",
            "          59       0.68      0.79      0.73        19\n",
            "          60       1.00      1.00      1.00        18\n",
            "          61       0.94      0.79      0.86        19\n",
            "          62       1.00      0.95      0.97        19\n",
            "          63       0.62      0.68      0.65        19\n",
            "\n",
            "    accuracy                           0.84      1076\n",
            "   macro avg       0.85      0.83      0.84      1076\n",
            "weighted avg       0.84      0.84      0.84      1076\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "# 1. Tạo một pipeline với TfidfVectorizer và LogisticRegression\n",
        "tfidf_lr_pipeline = make_pipeline(\n",
        "    TfidfVectorizer(max_features=5000),\n",
        "    LogisticRegression(max_iter=1000)\n",
        ")\n",
        "# 2. Huấn luyện pipeline trên tập train\n",
        "tfidf_lr_pipeline.fit(df_train['text'], df_train['label_encoded'])\n",
        "\n",
        "# 3. Đánh giá trên tập test\n",
        "y_pred = tfidf_lr_pipeline.predict(df_test['text'])\n",
        "print(classification_report(df_test['label_encoded'], y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2df43f57",
      "metadata": {
        "id": "2df43f57"
      },
      "source": [
        "### Pipeline Word2Vec (mean) + Dense layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "jxbc58CrmH78",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxbc58CrmH78",
        "outputId": "86c6448e-501f-4aa2-b433-6d31ff33547e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m83.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gensim\n",
            "Successfully installed gensim-4.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69efd1bf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69efd1bf",
        "outputId": "e5aee40a-ab02-4cd0-c516-3e2e0a1a48a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.1986 - loss: 3.4423 - val_accuracy: 0.6970 - val_loss: 1.4045\n",
            "Epoch 2/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5880 - loss: 1.5604 - val_accuracy: 0.7528 - val_loss: 0.9813\n",
            "Epoch 3/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6679 - loss: 1.2089 - val_accuracy: 0.7695 - val_loss: 0.8538\n",
            "Epoch 4/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6980 - loss: 1.0580 - val_accuracy: 0.7955 - val_loss: 0.7801\n",
            "Epoch 5/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7294 - loss: 0.9479 - val_accuracy: 0.8020 - val_loss: 0.7333\n",
            "Epoch 6/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7447 - loss: 0.9092 - val_accuracy: 0.8048 - val_loss: 0.7016\n",
            "Epoch 7/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7422 - loss: 0.8788 - val_accuracy: 0.8169 - val_loss: 0.6897\n",
            "Epoch 8/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7534 - loss: 0.8554 - val_accuracy: 0.8104 - val_loss: 0.6661\n",
            "Epoch 9/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7741 - loss: 0.7962 - val_accuracy: 0.8095 - val_loss: 0.6503\n",
            "Epoch 10/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7722 - loss: 0.7846 - val_accuracy: 0.8141 - val_loss: 0.6430\n",
            "Epoch 11/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7816 - loss: 0.7531 - val_accuracy: 0.8188 - val_loss: 0.6363\n",
            "Epoch 12/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7875 - loss: 0.7309 - val_accuracy: 0.8206 - val_loss: 0.6240\n",
            "Epoch 13/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7924 - loss: 0.7210 - val_accuracy: 0.8271 - val_loss: 0.6185\n",
            "Epoch 14/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7974 - loss: 0.7008 - val_accuracy: 0.8290 - val_loss: 0.6190\n",
            "Epoch 15/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8069 - loss: 0.6741 - val_accuracy: 0.8318 - val_loss: 0.6152\n",
            "Epoch 16/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7968 - loss: 0.6741 - val_accuracy: 0.8374 - val_loss: 0.6083\n",
            "Epoch 17/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8012 - loss: 0.6696 - val_accuracy: 0.8383 - val_loss: 0.6100\n",
            "Epoch 18/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8083 - loss: 0.6635 - val_accuracy: 0.8206 - val_loss: 0.6063\n",
            "Epoch 19/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8108 - loss: 0.6391 - val_accuracy: 0.8262 - val_loss: 0.5991\n",
            "Epoch 20/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8150 - loss: 0.6251 - val_accuracy: 0.8346 - val_loss: 0.5939\n",
            "Epoch 21/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8122 - loss: 0.6160 - val_accuracy: 0.8346 - val_loss: 0.5951\n",
            "Epoch 22/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8171 - loss: 0.6225 - val_accuracy: 0.8439 - val_loss: 0.5885\n",
            "Epoch 23/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8210 - loss: 0.6058 - val_accuracy: 0.8346 - val_loss: 0.5916\n",
            "Epoch 24/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8267 - loss: 0.5792 - val_accuracy: 0.8541 - val_loss: 0.5847\n",
            "Epoch 25/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8236 - loss: 0.5924 - val_accuracy: 0.8383 - val_loss: 0.5870\n",
            "Epoch 26/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8152 - loss: 0.5897 - val_accuracy: 0.8448 - val_loss: 0.5828\n",
            "Epoch 27/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8288 - loss: 0.5709 - val_accuracy: 0.8411 - val_loss: 0.5852\n",
            "Epoch 28/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8238 - loss: 0.5691 - val_accuracy: 0.8383 - val_loss: 0.5841\n",
            "Epoch 29/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8330 - loss: 0.5604 - val_accuracy: 0.8429 - val_loss: 0.5870\n",
            "Epoch 30/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8270 - loss: 0.5692 - val_accuracy: 0.8532 - val_loss: 0.5832\n",
            "Epoch 31/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8328 - loss: 0.5500 - val_accuracy: 0.8429 - val_loss: 0.5965\n",
            "Epoch 32/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8373 - loss: 0.5394 - val_accuracy: 0.8420 - val_loss: 0.5962\n",
            "Epoch 33/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8392 - loss: 0.5361 - val_accuracy: 0.8504 - val_loss: 0.5908\n",
            "Epoch 34/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8330 - loss: 0.5445 - val_accuracy: 0.8439 - val_loss: 0.5926\n",
            "Epoch 35/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8368 - loss: 0.5381 - val_accuracy: 0.8494 - val_loss: 0.5879\n",
            "Epoch 36/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8371 - loss: 0.5343 - val_accuracy: 0.8504 - val_loss: 0.5852\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.89      0.92        19\n",
            "           1       0.91      0.91      0.91        11\n",
            "           2       0.78      0.95      0.86        19\n",
            "           3       0.71      0.62      0.67         8\n",
            "           4       0.76      0.87      0.81        15\n",
            "           5       0.71      0.77      0.74        13\n",
            "           6       0.57      0.63      0.60        19\n",
            "           7       0.94      0.89      0.92        19\n",
            "           8       0.94      0.79      0.86        19\n",
            "           9       0.83      0.53      0.65        19\n",
            "          10       0.86      0.75      0.80         8\n",
            "          11       0.81      0.89      0.85        19\n",
            "          12       0.88      0.88      0.88         8\n",
            "          13       0.73      0.84      0.78        19\n",
            "          14       0.87      0.68      0.76        19\n",
            "          15       0.83      0.79      0.81        19\n",
            "          16       1.00      1.00      1.00        19\n",
            "          17       1.00      1.00      1.00        19\n",
            "          18       1.00      1.00      1.00        19\n",
            "          19       1.00      1.00      1.00        19\n",
            "          20       1.00      1.00      1.00        19\n",
            "          21       0.91      0.83      0.87        12\n",
            "          22       0.95      1.00      0.97        19\n",
            "          23       0.90      0.95      0.92        19\n",
            "          24       0.19      0.16      0.17        19\n",
            "          25       0.95      0.95      0.95        19\n",
            "          26       0.94      0.94      0.94        16\n",
            "          27       0.82      0.95      0.88        19\n",
            "          28       0.74      0.74      0.74        19\n",
            "          29       0.77      0.83      0.80        12\n",
            "          30       1.00      0.89      0.94        19\n",
            "          31       0.50      0.67      0.57         3\n",
            "          32       0.70      0.50      0.58        14\n",
            "          33       0.67      0.67      0.67         9\n",
            "          34       0.70      1.00      0.82         7\n",
            "          35       0.76      0.84      0.80        19\n",
            "          36       0.84      0.84      0.84        19\n",
            "          37       0.94      0.89      0.92        19\n",
            "          38       0.65      0.72      0.68        18\n",
            "          39       0.57      0.68      0.62        19\n",
            "          40       1.00      0.29      0.44         7\n",
            "          41       0.77      0.53      0.62        19\n",
            "          42       0.94      0.89      0.92        19\n",
            "          43       0.70      0.74      0.72        19\n",
            "          44       0.54      0.68      0.60        19\n",
            "          45       0.80      0.63      0.71        19\n",
            "          46       0.94      0.79      0.86        19\n",
            "          47       1.00      0.89      0.94        19\n",
            "          48       0.94      0.89      0.92        19\n",
            "          49       0.36      0.63      0.46        19\n",
            "          50       0.78      1.00      0.88        14\n",
            "          51       0.94      0.89      0.92        19\n",
            "          52       0.68      0.79      0.73        19\n",
            "          53       0.93      0.74      0.82        19\n",
            "          54       0.90      0.90      0.90        10\n",
            "          55       1.00      0.95      0.97        19\n",
            "          56       0.84      0.89      0.86        18\n",
            "          57       0.79      0.79      0.79        19\n",
            "          58       0.89      0.84      0.86        19\n",
            "          59       0.83      0.79      0.81        19\n",
            "          60       1.00      1.00      1.00        18\n",
            "          61       0.95      0.95      0.95        19\n",
            "          62       0.95      0.95      0.95        19\n",
            "          63       0.74      0.74      0.74        19\n",
            "\n",
            "    accuracy                           0.82      1076\n",
            "   macro avg       0.82      0.81      0.81      1076\n",
            "weighted avg       0.83      0.82      0.82      1076\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# 1. Huấn luyện mô hình Word2Vec trên dữ liệu text của bạn\n",
        "sentences = [text.split() for text in df_train['text']]\n",
        "w2v_model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4, epochs=100)\n",
        "\n",
        "# 2. Viết hàm để chuyển mỗi câu thành vector trung bình\n",
        "def sentence_to_avg_vector(text, model):\n",
        "    # ... (Implement logic)\n",
        "    vectors = [model.wv[word] for word in text.split() if word in model.wv]\n",
        "    avg_vector = np.mean(vectors, axis=0) if vectors else np.zeros(model.vector_size)\n",
        "    return avg_vector\n",
        "\n",
        "# 3. Tạo dữ liệu train/val/test X_train_avg, X_val_avg, X_test_avg\n",
        "X_train_avg = np.array([sentence_to_avg_vector(text, w2v_model) for text in df_train['text']])\n",
        "X_val_avg = np.array([sentence_to_avg_vector(text, w2v_model) for text in df_val['text']])\n",
        "X_test_avg = np.array([sentence_to_avg_vector(text, w2v_model) for text in df_test['text']])\n",
        "y_train = df_train['label_encoded'].values\n",
        "y_val = df_val['label_encoded'].values\n",
        "y_test = df_test['label_encoded'].values\n",
        "\n",
        "# 4. Xây dựng mô hình Sequential của Keras\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(w2v_model.vector_size,)),\n",
        "    Dropout(0.5),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# 5. Compile, huấn luyện và đánh giá mô hình\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "history = model.fit(\n",
        "    X_train_avg, y_train,\n",
        "    validation_data=(X_val_avg, y_val),\n",
        "    epochs=100, batch_size=32,\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "y_pred = model.predict(X_test_avg)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "print(classification_report(y_test, y_pred_classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CFcM2Q7UhTqy",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFcM2Q7UhTqy",
        "outputId": "1c1d18c6-d955-4ad1-d3ce-194019724582"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Log Loss on test set: 0.6701321601867676\n"
          ]
        }
      ],
      "source": [
        "# tính toán loss trên tập test\n",
        "y_pred_proba = model.predict(X_test_avg)\n",
        "log_loss = -np.mean(np.log(y_pred_proba[np.arange(len(y_test)), y_test]))\n",
        "print(f\"Log Loss on test set: {log_loss}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "669d60d0",
      "metadata": {
        "id": "669d60d0"
      },
      "source": [
        "### Mô hình nâng cao (Embedding pre-trained + LSTM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "caf7c6f6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 957
        },
        "id": "caf7c6f6",
        "outputId": "bd6684ac-c43a-4f2b-f466-b66191a4296e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 349ms/step - accuracy: 0.3748 - loss: 2.9687 - val_accuracy: 0.7686 - val_loss: 0.9300\n",
            "Epoch 2/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 341ms/step - accuracy: 0.7778 - loss: 0.9050 - val_accuracy: 0.8160 - val_loss: 0.6865\n",
            "Epoch 3/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 347ms/step - accuracy: 0.8195 - loss: 0.6701 - val_accuracy: 0.8327 - val_loss: 0.6053\n",
            "Epoch 4/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 346ms/step - accuracy: 0.8510 - loss: 0.5603 - val_accuracy: 0.8401 - val_loss: 0.5527\n",
            "Epoch 5/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 347ms/step - accuracy: 0.8627 - loss: 0.5020 - val_accuracy: 0.8485 - val_loss: 0.5401\n",
            "Epoch 6/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 347ms/step - accuracy: 0.8691 - loss: 0.4608 - val_accuracy: 0.8485 - val_loss: 0.5187\n",
            "Epoch 7/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 349ms/step - accuracy: 0.8900 - loss: 0.3964 - val_accuracy: 0.8578 - val_loss: 0.5060\n",
            "Epoch 8/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 349ms/step - accuracy: 0.8948 - loss: 0.3742 - val_accuracy: 0.8532 - val_loss: 0.4920\n",
            "Epoch 9/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 346ms/step - accuracy: 0.9015 - loss: 0.3561 - val_accuracy: 0.8634 - val_loss: 0.4815\n",
            "Epoch 10/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 345ms/step - accuracy: 0.9185 - loss: 0.3072 - val_accuracy: 0.8652 - val_loss: 0.4790\n",
            "Epoch 11/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 348ms/step - accuracy: 0.9216 - loss: 0.2860 - val_accuracy: 0.8708 - val_loss: 0.4688\n",
            "Epoch 12/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 346ms/step - accuracy: 0.9301 - loss: 0.2599 - val_accuracy: 0.8652 - val_loss: 0.4709\n",
            "Epoch 13/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 346ms/step - accuracy: 0.9351 - loss: 0.2416 - val_accuracy: 0.8690 - val_loss: 0.4723\n",
            "Epoch 14/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 340ms/step - accuracy: 0.9383 - loss: 0.2334 - val_accuracy: 0.8699 - val_loss: 0.4797\n",
            "Epoch 15/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 343ms/step - accuracy: 0.9389 - loss: 0.2171 - val_accuracy: 0.8708 - val_loss: 0.4764\n",
            "Epoch 16/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 342ms/step - accuracy: 0.9476 - loss: 0.2018 - val_accuracy: 0.8671 - val_loss: 0.4853\n",
            "Epoch 17/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 344ms/step - accuracy: 0.9491 - loss: 0.1844 - val_accuracy: 0.8773 - val_loss: 0.4726\n",
            "Epoch 18/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 349ms/step - accuracy: 0.9562 - loss: 0.1660 - val_accuracy: 0.8662 - val_loss: 0.4915\n",
            "Epoch 19/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 350ms/step - accuracy: 0.9530 - loss: 0.1714 - val_accuracy: 0.8699 - val_loss: 0.4876\n",
            "Epoch 20/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 351ms/step - accuracy: 0.9586 - loss: 0.1471 - val_accuracy: 0.8680 - val_loss: 0.4903\n",
            "Epoch 21/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 350ms/step - accuracy: 0.9601 - loss: 0.1489 - val_accuracy: 0.8680 - val_loss: 0.4893\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'classification_report' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1379507771.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstm_model_pretrained\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_pad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0my_pred_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'classification_report' is not defined"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM\n",
        "\n",
        "# 1. Tiền xử lý cho mô hình chuỗi\n",
        "# a. Tokenizer: Tạo vocab và chuyển text thành chuỗi chỉ số\n",
        "vocab_size = len(w2v_model.wv.index_to_key) + 1\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=\"<UNK>\")\n",
        "tokenizer.fit_on_texts(df_train['text'])\n",
        "train_sequences = tokenizer.texts_to_sequences(df_train['text'])\n",
        "# b. Padding: Đảm bảo các chuỗi có cùng độ dài\n",
        "max_len = 100\n",
        "X_train_pad = pad_sequences(train_sequences, maxlen=max_len, padding='post')\n",
        "val_sequences = tokenizer.texts_to_sequences(df_val['text'])\n",
        "X_val_pad = pad_sequences(val_sequences, maxlen=max_len, padding='post')\n",
        "test_sequences = tokenizer.texts_to_sequences(df_test['text'])\n",
        "X_test_pad = pad_sequences(test_sequences, maxlen=max_len, padding='post')\n",
        "\n",
        "# 2. Tạo ma trận trọng số cho Embedding Layer từ Word2Vec\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "embedding_dim = w2v_model.vector_size\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if word in w2v_model.wv:\n",
        "        embedding_matrix[i] = w2v_model.wv[word]\n",
        "\n",
        "# 3. Xây dựng mô hình Sequential với LSTM\n",
        "lstm_model_pretrained = Sequential([\n",
        "    Embedding(\n",
        "        input_dim=vocab_size,\n",
        "        output_dim=embedding_dim,\n",
        "        weights=[embedding_matrix], # Khởi tạo trọng số\n",
        "        input_length=max_len,\n",
        "        mask_zero=True,\n",
        "        trainable=False # Đóng băng lớp Embedding\n",
        "    ),\n",
        "    LSTM(128, dropout=0.2, recurrent_dropout=0.2),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# 4. Compile, huấn luyện (sử dụng EarlyStopping) và đánh giá\n",
        "lstm_model_pretrained.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "history = lstm_model_pretrained.fit(\n",
        "    X_train_pad, y_train,\n",
        "    validation_data=(X_val_pad, y_val),\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    callbacks=[early_stopping]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "nZBeTE7COVr9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZBeTE7COVr9",
        "outputId": "368d050d-437a-4fb6-a6d4-1984d1d3debc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 100ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.95      0.97        19\n",
            "           1       0.79      1.00      0.88        11\n",
            "           2       0.89      0.89      0.89        19\n",
            "           3       0.75      0.75      0.75         8\n",
            "           4       0.86      0.80      0.83        15\n",
            "           5       0.75      0.92      0.83        13\n",
            "           6       0.57      0.63      0.60        19\n",
            "           7       1.00      0.95      0.97        19\n",
            "           8       0.89      0.84      0.86        19\n",
            "           9       0.92      0.58      0.71        19\n",
            "          10       0.80      1.00      0.89         8\n",
            "          11       0.82      0.95      0.88        19\n",
            "          12       0.88      0.88      0.88         8\n",
            "          13       0.88      0.79      0.83        19\n",
            "          14       0.71      0.63      0.67        19\n",
            "          15       0.82      0.95      0.88        19\n",
            "          16       0.86      1.00      0.93        19\n",
            "          17       1.00      1.00      1.00        19\n",
            "          18       1.00      1.00      1.00        19\n",
            "          19       0.95      1.00      0.97        19\n",
            "          20       1.00      0.79      0.88        19\n",
            "          21       0.92      1.00      0.96        12\n",
            "          22       0.95      0.95      0.95        19\n",
            "          23       0.95      0.95      0.95        19\n",
            "          24       0.28      0.26      0.27        19\n",
            "          25       0.83      1.00      0.90        19\n",
            "          26       0.89      1.00      0.94        16\n",
            "          27       0.86      0.95      0.90        19\n",
            "          28       0.81      0.68      0.74        19\n",
            "          29       0.91      0.83      0.87        12\n",
            "          30       0.94      0.89      0.92        19\n",
            "          31       0.40      0.67      0.50         3\n",
            "          32       0.82      0.64      0.72        14\n",
            "          33       0.80      0.89      0.84         9\n",
            "          34       1.00      1.00      1.00         7\n",
            "          35       0.76      0.84      0.80        19\n",
            "          36       0.89      0.89      0.89        19\n",
            "          37       0.95      0.95      0.95        19\n",
            "          38       1.00      0.67      0.80        18\n",
            "          39       0.70      0.74      0.72        19\n",
            "          40       0.88      1.00      0.93         7\n",
            "          41       0.81      0.68      0.74        19\n",
            "          42       0.90      0.95      0.92        19\n",
            "          43       0.57      0.68      0.62        19\n",
            "          44       0.70      0.74      0.72        19\n",
            "          45       0.85      0.58      0.69        19\n",
            "          46       0.83      0.79      0.81        19\n",
            "          47       1.00      0.84      0.91        19\n",
            "          48       1.00      0.95      0.97        19\n",
            "          49       0.30      0.37      0.33        19\n",
            "          50       0.87      0.93      0.90        14\n",
            "          51       0.95      1.00      0.97        19\n",
            "          52       0.70      0.74      0.72        19\n",
            "          53       0.82      0.74      0.78        19\n",
            "          54       0.83      1.00      0.91        10\n",
            "          55       0.90      1.00      0.95        19\n",
            "          56       0.80      0.89      0.84        18\n",
            "          57       0.93      0.68      0.79        19\n",
            "          58       0.90      1.00      0.95        19\n",
            "          59       0.79      0.79      0.79        19\n",
            "          60       0.95      1.00      0.97        18\n",
            "          61       0.94      0.89      0.92        19\n",
            "          62       0.90      0.95      0.92        19\n",
            "          63       0.81      0.68      0.74        19\n",
            "\n",
            "    accuracy                           0.84      1076\n",
            "   macro avg       0.84      0.84      0.84      1076\n",
            "weighted avg       0.84      0.84      0.84      1076\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "y_pred = lstm_model_pretrained.predict(X_test_pad)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "print(classification_report(y_test, y_pred_classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "brSjwB-BoH2D",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brSjwB-BoH2D",
        "outputId": "4cf77691-63b8-4819-d184-99d7c81f4d7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step\n",
            "Log Loss on test set: 0.5620812773704529\n"
          ]
        }
      ],
      "source": [
        "# tính toán loss trên tập test\n",
        "y_pred_proba = lstm_model_pretrained.predict(X_test_pad)\n",
        "log_loss = -np.mean(np.log(y_pred_proba[np.arange(len(y_test)), y_test]))\n",
        "print(f\"Log Loss on test set: {log_loss}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tTVK5-yhn4Fd",
      "metadata": {
        "id": "tTVK5-yhn4Fd"
      },
      "source": [
        "### Mô hình nâng cao (Embedding học từ đầu + LSTM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "PyRbAuqpn8ZX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyRbAuqpn8ZX",
        "outputId": "e59222ef-4ffe-48db-bb28-339d3c02f4e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 393ms/step - accuracy: 0.1372 - loss: 3.7876 - val_accuracy: 0.5781 - val_loss: 1.8261\n",
            "Epoch 2/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 387ms/step - accuracy: 0.6381 - loss: 1.5643 - val_accuracy: 0.7779 - val_loss: 0.9589\n",
            "Epoch 3/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 384ms/step - accuracy: 0.8259 - loss: 0.7729 - val_accuracy: 0.8262 - val_loss: 0.6904\n",
            "Epoch 4/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 401ms/step - accuracy: 0.9030 - loss: 0.4482 - val_accuracy: 0.8411 - val_loss: 0.5988\n",
            "Epoch 5/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 382ms/step - accuracy: 0.9391 - loss: 0.3049 - val_accuracy: 0.8606 - val_loss: 0.5322\n",
            "Epoch 6/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 386ms/step - accuracy: 0.9520 - loss: 0.2210 - val_accuracy: 0.8559 - val_loss: 0.5248\n",
            "Epoch 7/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 380ms/step - accuracy: 0.9648 - loss: 0.1673 - val_accuracy: 0.8634 - val_loss: 0.5157\n",
            "Epoch 8/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 380ms/step - accuracy: 0.9747 - loss: 0.1252 - val_accuracy: 0.8625 - val_loss: 0.5228\n",
            "Epoch 9/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 383ms/step - accuracy: 0.9798 - loss: 0.1020 - val_accuracy: 0.8615 - val_loss: 0.5252\n",
            "Epoch 10/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 384ms/step - accuracy: 0.9823 - loss: 0.0851 - val_accuracy: 0.8559 - val_loss: 0.5363\n",
            "Epoch 11/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 386ms/step - accuracy: 0.9835 - loss: 0.0766 - val_accuracy: 0.8690 - val_loss: 0.5022\n",
            "Epoch 12/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 385ms/step - accuracy: 0.9869 - loss: 0.0622 - val_accuracy: 0.8634 - val_loss: 0.5374\n",
            "Epoch 13/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 383ms/step - accuracy: 0.9891 - loss: 0.0541 - val_accuracy: 0.8597 - val_loss: 0.5571\n",
            "Epoch 14/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 384ms/step - accuracy: 0.9920 - loss: 0.0422 - val_accuracy: 0.8652 - val_loss: 0.5478\n",
            "Epoch 15/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 381ms/step - accuracy: 0.9909 - loss: 0.0432 - val_accuracy: 0.8662 - val_loss: 0.5733\n",
            "Epoch 16/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 406ms/step - accuracy: 0.9886 - loss: 0.0478 - val_accuracy: 0.8615 - val_loss: 0.5719\n",
            "Epoch 17/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 383ms/step - accuracy: 0.9922 - loss: 0.0324 - val_accuracy: 0.8662 - val_loss: 0.5701\n",
            "Epoch 18/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 387ms/step - accuracy: 0.9946 - loss: 0.0269 - val_accuracy: 0.8671 - val_loss: 0.5602\n",
            "Epoch 19/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 386ms/step - accuracy: 0.9946 - loss: 0.0260 - val_accuracy: 0.8690 - val_loss: 0.5759\n",
            "Epoch 20/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 387ms/step - accuracy: 0.9944 - loss: 0.0235 - val_accuracy: 0.8745 - val_loss: 0.5808\n",
            "Epoch 21/100\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 388ms/step - accuracy: 0.9955 - loss: 0.0180 - val_accuracy: 0.8671 - val_loss: 0.6059\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 68ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.95      0.92        19\n",
            "           1       1.00      1.00      1.00        11\n",
            "           2       0.86      0.95      0.90        19\n",
            "           3       1.00      0.88      0.93         8\n",
            "           4       1.00      0.87      0.93        15\n",
            "           5       0.81      1.00      0.90        13\n",
            "           6       0.47      0.47      0.47        19\n",
            "           7       0.82      0.95      0.88        19\n",
            "           8       0.72      0.68      0.70        19\n",
            "           9       0.93      0.68      0.79        19\n",
            "          10       0.70      0.88      0.78         8\n",
            "          11       0.85      0.89      0.87        19\n",
            "          12       0.70      0.88      0.78         8\n",
            "          13       0.83      1.00      0.90        19\n",
            "          14       0.68      0.68      0.68        19\n",
            "          15       1.00      0.89      0.94        19\n",
            "          16       1.00      1.00      1.00        19\n",
            "          17       1.00      1.00      1.00        19\n",
            "          18       0.95      1.00      0.97        19\n",
            "          19       1.00      1.00      1.00        19\n",
            "          20       1.00      0.95      0.97        19\n",
            "          21       1.00      1.00      1.00        12\n",
            "          22       0.95      1.00      0.97        19\n",
            "          23       0.95      1.00      0.97        19\n",
            "          24       0.32      0.32      0.32        19\n",
            "          25       1.00      1.00      1.00        19\n",
            "          26       1.00      1.00      1.00        16\n",
            "          27       1.00      0.89      0.94        19\n",
            "          28       0.79      0.79      0.79        19\n",
            "          29       0.92      0.92      0.92        12\n",
            "          30       0.94      0.89      0.92        19\n",
            "          31       0.75      1.00      0.86         3\n",
            "          32       1.00      0.71      0.83        14\n",
            "          33       0.80      0.89      0.84         9\n",
            "          34       0.86      0.86      0.86         7\n",
            "          35       0.76      0.84      0.80        19\n",
            "          36       0.76      0.84      0.80        19\n",
            "          37       1.00      0.89      0.94        19\n",
            "          38       0.68      0.83      0.75        18\n",
            "          39       0.80      0.63      0.71        19\n",
            "          40       1.00      1.00      1.00         7\n",
            "          41       0.68      0.68      0.68        19\n",
            "          42       1.00      0.89      0.94        19\n",
            "          43       0.80      0.63      0.71        19\n",
            "          44       0.68      0.68      0.68        19\n",
            "          45       1.00      0.84      0.91        19\n",
            "          46       0.89      0.84      0.86        19\n",
            "          47       1.00      0.95      0.97        19\n",
            "          48       0.76      1.00      0.86        19\n",
            "          49       0.54      0.37      0.44        19\n",
            "          50       0.87      0.93      0.90        14\n",
            "          51       0.90      0.95      0.92        19\n",
            "          52       0.83      0.79      0.81        19\n",
            "          53       0.81      0.68      0.74        19\n",
            "          54       0.89      0.80      0.84        10\n",
            "          55       0.90      0.95      0.92        19\n",
            "          56       0.80      0.89      0.84        18\n",
            "          57       0.80      0.84      0.82        19\n",
            "          58       0.84      0.84      0.84        19\n",
            "          59       0.70      0.84      0.76        19\n",
            "          60       0.90      1.00      0.95        18\n",
            "          61       1.00      0.89      0.94        19\n",
            "          62       1.00      0.95      0.97        19\n",
            "          63       0.70      0.74      0.72        19\n",
            "\n",
            "    accuracy                           0.85      1076\n",
            "   macro avg       0.86      0.86      0.85      1076\n",
            "weighted avg       0.85      0.85      0.85      1076\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Dữ liệu đã được tiền xử lý (tokenized, padded) từ nhiệm vụ 3\n",
        "# 1. Xây dựng mô hình\n",
        "lstm_model_scratch = Sequential([\n",
        "    Embedding(\n",
        "        input_dim=vocab_size,\n",
        "        output_dim=100, # Chọn một chiều embedding, ví dụ 100\n",
        "        input_length=max_len,\n",
        "        mask_zero=True,\n",
        "        # Không có weights, trainable=True (mặc định)\n",
        "    ),\n",
        "    LSTM(128, dropout=0.2, recurrent_dropout=0.2),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# 2. Compile, huấn luyện và đánh giá mô hình\n",
        "lstm_model_scratch.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "history = lstm_model_scratch.fit(\n",
        "    X_train_pad, y_train,\n",
        "    validation_data=(X_val_pad, y_val),\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "y_pred = lstm_model_scratch.predict(X_test_pad)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "print(classification_report(y_test, y_pred_classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "_iQndeTLVwEa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iQndeTLVwEa",
        "outputId": "74ea2c9f-47b3-49dd-cb23-1ffa460652d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step\n",
            "Log Loss on test set: 0.6144747138023376\n"
          ]
        }
      ],
      "source": [
        "# tính toán loss trên tập test\n",
        "y_pred_proba = lstm_model_scratch.predict(X_test_pad)\n",
        "log_loss = -np.mean(np.log(y_pred_proba[np.arange(len(y_test)), y_test]))\n",
        "print(f\"Log Loss on test set: {log_loss}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
